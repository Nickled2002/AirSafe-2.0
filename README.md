
3D terrain modelling used in light aircraft visibility aid 

Nikolaos Ledakis Engonopoulos

BSc (Hons) Computing, 2024














 




School of Design and Informatics
Abertay University
 
Table of Contents
Table of Figures	ii
Table of Tables	iii
Acknowledgements	iv
Abstract	v
Abbreviations, Symbols and Notation	vii
Chapter 1 Introduction	1
Chapter 2 Literature Review	4
Chapter 3 Methodology	9
Chapter 4 Results	23
Chapter 5 Discussion	28
Chapter 6 Conclusion and Future Work	35
List of References	38
Appendices	40
  
Table of Figures
Figure 2.1- SRTM bounding box	7
Figure 3.1- Initial screeschot 	11
Figure 3.2- First 1 by 1 and 3 by 3 render	13
Figure 3.3- Improved 1 by 1 render	13
Figure 3.4- Cyclical camera pattern	21
Figure 4.1- North-East side of Isle of Arran (with and without texturing)	25
Figure 4.2- North-East side Isle of Arran comparison	25
Figure 4.3- Satelite view render 1	26
Figure 4.4- Topography Map comparison	26
Figure 4.5- Satelite view render 2	27
Figure 4.6- Satelite view render 2 comparison	27
Figure 5.1- Varying LOD collage	29
Figure 5.2- LOD2 (increment 3)	30

 
Table of Tables
Table 3.1- Initial keyboard inputs	14
Table 3.2- 3x3 matrix latitude, longitude to cardinal direction	18
Table 4.1- FPS measurments	24
Table 6.1- Final keyboard inputs	36

 
Acknowledgements
I would like to especially thank Dr Ian Ferguson for his supervision on this project and for his guidance, expertise, and support throughout this challenging but also very exciting process.

 
Abstract
CONTEXT: Aviation using light aircrafts is crucial for society to function. As the hardware aspect of those aircrafts improve throughout the years, the software aspect also needs to remain up to date in order for the functions provided to be working as efficiently as possible. Airsafe is a 3D terrain visualisation prototype built in the late 2000s using a now deprecated API for the purpose of modelling the terrain. This prevents the prototype from being optimised and rearchitected for more modern hardware. A more modern low-level language with a modern modelling API will be required to redevelop the prototype in such a way that it can be optimised, while also having the possibility of it being reworked on throughout the following years with the purpose of adapting it to advancements in hardware technology.
AIM: Using Rust and WGPU to re-architecture and rebuild the original Airsafe prototype. So, this will result in a program adapted to modern low-end hardware, while also being maintainable throughout the years to come.
METHOD: The original Airsafe prototype was studied to determine the cooperation of Java with Java3D, and its additional features were taken into consideration while also analysing the original architecture used. The basic method of visualisation was studied and compared to recent research development in the process of visualisation of Geographic Information Systems, such as varying LOD and use of multiple chunks. The Rust programming language’s and WGPU’s core concepts were also studied. A working prototype was then developed, incorporating all the research done with all features determined to improve the efficiency. This was implemented and tested to establish the level of efficiency achieved.
RESULTS: The modernised and original Airsafe versions were compared, and both performances were analysed in metrics of performance and accuracy to the real-world terrain depicted. The result proved the modernised version to be highly more efficient in its rendering process, while also showcasing the evolution in the process of developing low-level software and low-end hardware since the initial development of the prototype.
CONCLUSION: This project was determined successful as the aims that were set were achieved, and this allowed for the improvement of the original rendering process, incorporating new hardware architecture, programming language and graphics API with longevity, efficiency and accuracy as its main goals.
 
Abbreviations, Symbols and Notation
API		Application Programming Interface
CPU		Central Processing Unit
GPU		Graphics Processing Unit
SRTM		Shuttle Radar Topography Mission 
WGPU	WebGPU Rust crate
DEM		Digital Elevation Model
WGSL 	WebGPU Shading Language 
FPS 		Frames per second

 
Chapter 1 Introduction
1.1 Light aircraft visual aid
Light aircraft aviation is essential in humanity’s day to day life. It is used for safety purposes such as in aerial firefighting and medical services, and in general community support such as agricultural services or even in provision of necessary supplies in rural areas (Air Transport Action Group, 2016). Light aircrafts are required to be as compact as possible for the purposes of minimizing flight time and fuel cost during the journey while also maintaining safety of the passengers and of the aircraft. Stability of day-to-day life in so many sectors depend on the safe transport of light aircrafts due to the massive use of aviation in society. 
However, when the environment doesn’t allow for ideal visibility of the path, the security of the aircraft, cargo and passengers is put at risk. This could in turn render the flight of an aircraft impossible in situations where their use is essential. On larger scale crafts this phenomenon is combatted using aeronautical charts that allow the pilot to map the trajectory of the plane. This system can also be applied to lighter crafts. However, due to the altitude and nature of flight paths they take, this system is not considered as efficient for lighter crafts. Another possible solution to this problem is with the use of multiple Electronic Flight Instrument System displays and combining information from the Multi-Function Display to map the topography of the environment (Universal Avionics, 2020). This process requires vast knowledge in the field and can be time consuming in the event of an emergency.
To combat this phenomenon Airsafe was developed. It was a prototype that mapped terrain into a 3-dimensional model that the pilot could use when the visibility was poor allowing for the visualization of the path of the aircraft. Due to the nature of the goal this project was trying to achieve, it was developed and designed for low end hardware. This prototype was built in the late 2000s, however as technology improves hardware becomes more efficient. Improvements to the program are also necessary, with updates required in the language and APIs used in the prototype. This ensures the program runs as efficiently as possible with the lowest end hardware. 
The original Airsafe prototype used a geographical terrain model and a Global Positioning System to render a real-time three-dimensional terrain model. It was built using the Java programming language with the Java3D API to model the terrain with the architectural standards of the hardware of the late 2000s era. However, the Java 3D API has since been deprecated meaning that it is no longer maintained. This impacts the performance of the prototype and does not allow for further improvements as the definition of low-spec hardware changes over the years.
1.2 Terrain Generation in an efficient manner
The biggest bottleneck this project runs into is during the rendering process when representing the terrain. Due to the nature and quantity of the data required for a detailed render of the terrain, the process of rendering requires a lot of computational effort. The hardware used in the aircraft device to run the program is assumed to be of similar strength as an average laptop. Therefore, the process of rendering the terrain needs to be as efficient as possible as to not hinder the process of piloting the aircraft while using the product.
1.3 Aim of the project
This project aims to modernise the original AirSafe prototype using a programming language and graphics API that have been actively maintained and are up to date with current generation hardware. This will be achieved by:
	Making an informed decision on the programming language and graphics rendering API. This decision will be based on their efficiency and high level of control over the computer’s resources. The speculated longevity of their lifecycle based on their current use must also be considered.
	Studying and understanding the basic concepts of rendering graphics with the chosen API in order to render the process of modelling the ground as efficiently as possible.
	Researching possible ways that the Earth’s geographical data can be retrieved and used for the purpose of 3D modelling the ground accurately.
	Identifying the most efficient way that the aircrafts useful data, such as the position in a Latitude and Longitude format or its altitude, can be retrieved and used by the product.
	Implementing all the researched topics into one product in the language and API chosen in an efficiently architectured manner, while also keeping the accuracy of the depicted terrain as high as possible.
1.4 Overview
This study revisited the original AirSafe project with the goal of its modernisation on current gen low-end hardware using a modern programming language -Rust- with a modern graphics API -WGPU-. This was done with the aim of making the rendering process as efficient as possible with varying results that are discussed in Chapter 4 and Chapter 5.
	To achieve this goal, significant research was made in all sectors involved in this artefact (the programming language, graphics API, efficient rendering etc.) shown in Chapter 2. The implementation of each iteration is analytically discussed in Chapter 3. Finally, an overall conclusion and potential future additions are discussed in Chapter 6. 
 
Chapter 2 Literature Review
This chapter demonstrates the crucial components that required in depth research during the development of this project. These components were used to develop the project in the most efficient manner possible individually, but also in accordance with each other to allow for a program that operates in the most efficient manner possible as a whole. This criterion is due to the nature of the project requiring real time terrain generation as the light aircraft would traverse new terrain.
2.1 Rust
Using Rust as the main programming language allows for the focus of the project to be placed on performance, safety and most importantly concurrency, allowing for the program to be high performing without requiring high end hardware. Rust also demonstrates promising longevity as a low-level language being the second language along with C to be added to the Linux Kernel Support (Linus Torvalds, 2022). In order to understand this fairly new programming language in depth two books were used. “Rust Programming Language” (The Rust Programming Language, no date) and “Rust Programming Language by Example” (Rust By Example, no date) which allowed for a more in depth understanding of the core concepts used such as the concept of ownership, the process of threading both on the CPU and GPU and the use of structs. 
2.2 WGPU by example
WGPU is a cargo crate that allows for the rendering of graphics both on the CPU and GPU. This crate played a significant role in the process of developing this project allowing for resource efficient graphics rendering. The crate allowed rendering of the terrain in the most efficient manner possible while maintaining a high level of detail, and also ensured that the application would be easy to use and the terrain easy to read. These concepts were learnt using “WGPU by Examples” (Jack Xu, 2023) starting from the basic concepts such as the rendering process through the use of render pipelines and render passes. Following this, the use of GPU buffers in the process of rendering basic shapes using triangle primitives allowed for the rendering of a shape using a multitude of vertices comprised of triangles forming a uniform area rendered. After 3D shapes or surfaces were rendered, lighting and shading were applied to add another level of realism to the rendered object. In order to add an even more in depth level of detail that would allow the user to read the objects shown through the terrain generation, textures and colour map data were implemented. These concepts could be applied differently on both 3D surface rendering and any other graphics. Finally, the concept of marching cubes and the use of voxels for 3D surfaces was studied for a potential implementation of a more sophisticated 3D terrain generation. This would contain all data in a 3D grid of voxels rather than a 2D grid of height values. This concept would not be implemented in the final solution of the project due to the fact that it adds another level of complexity and does not provide significant levels of detail for the specific use case. However, it allowed for a higher level of understanding of the overall improvement of efficiency of the rendering process.
2.3 Rendering terrain
The process of rendering accurate terrain for the purposes of a real-time mapping system requires data that represents the planet to be utilised for the purposes of accurately portraying Earth’s terrain. In this study “Real-time Terrain Mapping” (Bernardin et al., 2010), where the process of rendering and mapping terrain requires utmost efficiency, the use of digital elevation models (DEMs) was suggested. A digital elevation model is a bare topographic representation of the earth’s surface which does not include any surface man-made objects such as buildings, or natural objects, such as trees. In this study, a DEM representing height values for a specific latitude longitude quadrant is used. Colour was then assigned based on the resulting height. While this study focuses on terrain generation along a vertical cross-section of the surface, the process of how terrain rendering is optimised can be adapted for this specific use case. This study utilises a calculation to determine the level of detail (LOD) for each node to be rendered depending on the user’s position. This calculation allows for the efficient rendering of the terrain through a multi resolution terrain representation, allowing for a decreased level of detail the further away the node is from the view camera. This LOD calculation can be adapted to an x and z axis, with the use of chunks to reduce the complexity of the nodes further away with the goal of optimising the rendering of large terrains. Furthermore, as the camera position moves and approaches lower quality chunks, the LOD calculation can take place once more, with new chunks generated considered in the calculations. 
The process of rendering in this study commences with the calculation of the height value based on x and y coordinates, and obtaining their vertex normal that will then be stored in a vertex array along with the position and the texture coordinates. Those calculations are in turn rendered through a render pass in a front to back manner, making use of the graphics hardware depth buffer culling which ensures only the visible coordinates are rendered. This process ensures time and resources are not wasted in rendering unused coordinates. Following this, a second render pass is used for the purposes of making sure the LOD chunks are rendered without any cracks. The implementation of a second render pass is utilised for threading purposes increasing efficiency.
Subsequently on this study it was noted that the size of the DEM used would affect the performance of the application. This was tested by comparing data sets with varying DEM size and texture size and noting the processing times required for the rendering process along with the average frame rate of the render. It was determined that with a larger data set the build time increased while the average frames per second decreased.
2.4 SRTM
The Shuttle Radar Topography Mission (SRTM) was a mission led by National Aeronautics and Space Administration (NASA) and the National Geospatial-Intelligence Agency (NGA) (USGS, 2008). This mission’s goal was to create a topography of the Earth and capture the land elevations of the ground across the whole planet. The mission took place in February 2000, and utilised a shuttle that would be flown around the globe, using a set of antennas to capture the Earth’s topography. This mission resulted in over 80% of the Earth’s land (Figure 2.1) mass being added to the Earth’s digital elevation model in the form of height measurements. These height measurements were analysed and worked on to cover void areas and render the sea level as zero, due to the focus of the mission being on the topography of the land. The finalized version of these measurements were released in 2006, with thousands of files separating the Earth’s land mass in granules - each covering one-degree of latitude by one-degree of longitude for an easier ingestion of the data. Those files had their own dedicated file format ‘.hgt’ which stands for height, and allows for only certain applications to access the data while also allowing certain programming languages the ability to read the y values that correspond to specific x and z values.
 
Figure 2.1- SRTM mission bounding box taken from “Nasa.gov” 

2.5 Panel Instruments of a light aircraft
Based on this article from the Smithsonian Institution (Instruments | How Things Fly, no date), the panel of a light aircraft consists of six key instruments that provide information ensuring the safety of the aircraft and of the pilot. These consist of the airspeed indicator, the attitude indicator, an altimeter, a turn coordinator, a heading indicator, and a vertical speed indicator. Three different instruments could provide useful information in the implementation of the platform. Firstly, an altimeter, which is an instrument used to determine the altitude of the aircraft. Secondly, a heading indicator, which utilises a gyroscope to showcase the cardinal direction the aircraft is heading in. Finally, the attitude indicator, which once again utilises a gyroscope to demonstrate the aircraft’s position against the horizon. Although these instruments are analogue, this project could make use of them through an analogue to digital converter.
2.6 Original AirSafe project
The focus of the original AirSafe project (Liam McBrien, 2009) was set on the development of a system that would read data from a DEM and render it in real-time. This system would utilise a Global Positioning System (GPS) to determine and update the location of the user. In addition to these implementations this system also utilise HUD elements to aid in process of a pilot determining their surroundings as well as a top down satellite view for the same purpose. A map texture encompassed the rendered surface for the purpose of showcasing depth in higher detail and to provide additional information to the aircraft’s pilot. While the author considered the implementation of varying LOD to improve the efficiency of their rendering process at the time this was not possible due to Java3D requiring “all detail levels to be loaded into memory simultaneously” which was proved to not improve efficiency.
This implementation utilises different data sources with varying sizes to alternate between the level of detail provided ranging from 9GB for the lowest detail up to 160 GB for the highest. Additionally, when testing the Airsafe prototype on its lowest level of detail the most amount of frames per second that could be reached was 60 ( run in the a highest spec machine available to the author at the time). This high level of performance was also accompanied by a high level of recognisability of not only the environmental topography such as the mountain “Cobbler” but also of certain man-made structures such as airports runways, roads bridges etc. This can be attributed to the detailed overlay of a map as a texture over the rendered objects. 
Chapter 3 Methodology
This chapter depicts the phases undertaken for the implementation of the 3D terrain modelling software for light aircrafts. The methodology adopted for the development of this project was Agile. This decision was based on the nature of the project and the efficiency in which its development can be subdivided into smaller objectives. Each iteration of a smaller objective was planned, designed, implemented and tested so it could then be incorporated into the final implementation of the project. Once said objectives were completed, they could be subjected to varying levels of change in light of new information, but nonetheless they contribute to the overall completion of the final deliverable.
3.1 Basic Rendering With WGPU
WGPU is a crucial rust crate in the implementation of this artefact. It is based on the WebGPU API and is adapted for the Rust programming language, which allows for the rendering of general purpose graphics both on GPU and CPU. This library has been used in multiple large scale projects ranging from the gaming sphere, such as the Bevy game engine (Bevy Engine, 2024) or Veloren, a multiplayer voxel RPG that utilises WGPU for a large 3D terrain render (Veloren, 2019). It is also used in powerful general-purpose visualisation software such as nbodysim - a 3D N-Body simulation software (Kösters, 2024) - to glx, an open street map renderer that uses geographical data for its rendering process (Kernfeld, 2024). This library allows for the use of Vulkan, Metal, DirectX 12, and OpenGL ES in the process of rendering graphics. With the presence of such large-scale products that utilise WGPU, it is safe to assume that this library will be actively maintained for the foreseeable future. Additionally, WGPU allows for the separation of resource management, pre-execution preparation and execution to the processing unit contrary to many popular graphics APIs such as OpenGL, where a context object is utilised for all three above-mentioned processes. This will allow for a more efficient rendering process overall.
The initial implementation of WGPU was used to grasp the most commonly used concepts of the graphics API, and to test the capabilities of the library in the process of rendering. This ensured that it could be efficiently implemented in the project’s final iteration. Rust structs were utilised to initialise the core concepts whose declaration process remains unchanged. A struct in the rust programming language allows for the allocation of data in specific variables, and is not constricted to a specific data type. By referencing the struct along with the name of the variable required it can be read throughout the entire rendering process and can additionally be altered depending on the rendering process’s requirements, while simultaneously being maintained in the memory allocation. Finally, a struct allows for the creation of functions within the struct that can be referenced in the same manner as the variables within the same struct. One of these functions is called a default function which is utilised to instantiate all required variables. Similarly, a struct was used for the creation of new and use of Render pipelines, which allowed for the input of a set of operations to be executed, allowing for the rendering of a scene to be executed in Render Passes. A Render Pass enables the execution of the operations in a single render pipeline. Their collection produces the rendering of a scene outputted as an image. 
The use of shaders can be utilised for multiple operations such as the computing of the lighting on the rendered object, or the vertices utilised for its rendering, and is written in the WebGPU Shading Language (WGSL). In this case a shader was used for the purposes of generating the colour based on the position of the instance. However, on later iterations for the use of multiple chunks to render the terrain, the model matrix was calculated for each instance within the shader as well. To add a level of realism, a colourmap was created that would assign certain rgb values to each xyz position based on the height value within y. Additionally, buffers were used for the purpose of storing data to the GPU that was utilised in the rendering process. These buffers would be kept the same throughout all rendering processes unless instructed for new data to be queued in them. These data buffers consisted of the model, indices, and surface vertex buffer. The model buffer stored all the model data which consisted of matrixes that allowed for the depiction of the terrain from the point of view of the camera in a manner that emulates terrain in real life. The vertex buffer stored vectors that represented a height map of the surface to be rendered. This consisted of x, y and z values that created triangle primitives connecting all points of the height map forming a continuous surface. The index buffer was used to store calculated indices that aid in the triangle primitive creation process, making it more efficient. If said indices weren’t used, some vertex points would have to be stored multiple times during the triangle primitive creation process, as they would be utilised for multiple triangles, thus requiring a significant amount of supplementary memory allocated to the vertex buffer. 
This initial implementation consisted of the generation of a 3D surface (Figure 3.1) that represents a peak and a lake using the following mathematical function.
〖y=3(1-x)〗^2 e^(-(x^2+(z+1)^2))-10(x/5-x^3-z^5 ) e^(〖-x〗^2-z^2 )-1/3 e^(-(x+1)^2-z^2 )
The x and z values correspond to coordinates along the rendered square, and using the y values calculated, the height map is created. The xyz points form vertices that are connected to one another in pairs of three, hence generating the triangle primitives allowing for the rendering of that specific surface. This process is repeated for all vertices on the plain, thus rendering the equation as a 3D surface. 
Figure 3.1- Screenshot from rust program imitating peaks and valleys
3.2 SRTM data
To accurately depict the Earths terrain in this artefact, the data from the Shuttle Radar Topography Mission (SRTM) was used. The final and most accurate version of this dataset contains 14,297 granules. These granules consist of square plots of land with x, y and z values corresponding to the Earth’s topography, which are contained within a file with the .hgt file extension (corresponding to height). These files are named after the latitude and longitude coordinates they represent. To be able to access and use the data from the aforementioned files, the “srtm” rust crate was used(Jochen Gortler, 2018). This allowed rust to seamlessly unwrap the .hgt files and retrieve y values for corresponding x and z values, thus enabling the creation of a height map that was then rendered into the 3D terrain. However, this dataset omits certain areas of the earths topography where the granule only contains the sea level data. Therefore, a new .hgt file needed to be created containing just the value ‘0.0’ for all inputs of x and z, which allowed for the rust application to unwrap as a default file if no corresponding file to the users coordinates exists. Finally, the rust application was refactored to initially display a 1 by 1 tile of the srtm coordinates which displayed the following (Figure 3.2). On following iterations of the application, a larger area of granule rendering was effectuated with a 3 by 3 granule tile area being implemented as a final iteration (Figure 3.2). However, it was determined that the 3 by 3 granule tile covered too large a geographical area, spanning multiple kilometres in diameter in the same small quadrant. Therefore, a larger scale 1 by 1 granule tile was determined to be more usable, but contrary to the previous iteration this tile spanned a larger size consisting of more vector points demonstrating the terrain in a more realistic manner (Figure 3.3).
   
Figure 3.2- On the left 1 by 1 SRTM tile generates on the right 3 by 3 tile
 
Figure 3.3- Improved 1 by 1 tile
3.3 WASD Key Implementation
For the purposes of testing and evaluating the rendering process, a way of traversing the terrain needed to be implemented which did not require the traversal of multiple latitude and longitude granules in real time. This process was achieved with the addition of key inputs. Pressing a certain key while the application is running would alter the camera position as desired (Table 3.1).  




Key Pressed	Function Triggered
W	Moves the camera position 1/10th of a tile positively along the x axis
A	Moves the camera position 1/10th of a tile negatively along the z axis
S	Moves the camera position 1/10th of a tile negatively along the x axis
D	Moves the camera position 1/10th of a tile positively along the z axis
Q	Moves the camera position 1/10th of a tile positively along the y axis
E	Moves the camera position 1/10th of a tile negatively along the y axis
R	Moves the camera look direction positively along the y axis
F	Moves the camera look direction negatively along the y axis
Z	Moves the camera look direction positively along the x axis
X	Moves the camera look direction negatively along the y axis
Table 3.1- Keyboard inputs 
However, in a later iteration this implementation was altered to change the ground position while the camera position remained the same. Using this method rather than using keys to change the camera position enabled the rendering of new tile chunks to be more efficient.
3.4 Improving Rendering Process
The initial process of rendering terrain was completed but the process itself proved to be inefficient. However, some actions could be taken to improve its efficiency.
LOD and Chunk usage
Through reviewing multiple papers and books on the topic of 3D rendering, specifically in the terrain rendering domain, it was determined that an implementation that significantly improved the performance and efficiency of the rendering process was level of detail (LOD), along with the use of loadable and unloadable chunks. The LOD algorithm allows for adjustment of the complexity of the graphic rendered based on the distance from the point of viewing. To achieve this, the process of rendering a new chunk was restructured. Previously, when loading the terrain, the program would iterate through every vertex along the graphic meaning that for all points along the x axis and z axis a y point would need to be calculated and assigned to the height map. This process provided a very detailed render of the terrain but would slow down the entire rendering process. To reduce the computational resources required for this process, an increment was introduced to the vertex calculation function. Depending on how far a chunk was from the user, it would be assigned a level of detail with a number ranging from zero to five. The increment of iteration is calculated by adding one to the level of detail which would reduce the number of iterations per chunk, therefore reducing the total number of vertices needed to be calculated. 
Along with the level of detail algorithm, the use of chunks was determined to have significant improvement on the performance of the rendering process. A chunk is a segment of the overall terrain that will be loaded. Each chunk’s vertex data is calculated and rendered separately, and the entire collection of chunks is combined to portray the desired terrain. The use of chunks allows for their unloading and loading depending on their visibility based on the users point of view. To further simplify the process of generating new chunks multiple instances of a terrain chunk are created. This process is used to reduce the resources needed for generating each chunk. Therefore, if a chunk has been generated once, the user can move around on it as much as they like without having to recreate the terrain. Finally, the positioning of the chunk based on the user is utilized for the purposes of efficiently implementing the LOD algorithm. A lower level of detail on the chunks that are further away would not hinder the user experience since the further away a chunk is the less visible it becomes to the user.
SRTM Lookup Process
	The process of retrieving the y values from the srtm data proved to be very costly time and resource wise. This was due to the fact that the .hgt file had to be accessed every time a y value needed to be found. Additionally, the original process proved to be very inconsistent with the peaks and valleys depicted from the srtm data due to the fact that the normalisation process would take place on each chunk separately. This was remedied by abstracting the process of retrieving the srtm data from the hgt files, and normalising the data to a different function. This function can then only be called when the first initialisation of the terrain needs to happen, or when new srtm tiles need to be used. This drastically increased the efficiency of the program. This level of abstraction was done through the use of structs where the srtm data was stored in a vector of vectors named “mappeddata” where the x and z values used to retrieve the data corresponded to the position on the vector. At that point, the “mappeddata” values were returned from that calculation function and the struct would then store the values found, which in turn meant the values could be retrieved more efficiently just by using the x and z values as an index in “mappeddata”. This level of abstraction was also done with the hopes of multi-threading the process of calculating the “mappeddata” value for new srtm data that would be needed in the process of rendering new tiles outside of the scope of the current latitude and longitude coordinates.
Multiple Threads
To further increase the artefacts efficiency, threads were used. Threading allows for the simultaneous execution of a process, reducing the overall time required for it to execute. Multiple threads were used to execute the SRTM lookup process for multiple tiles, improving the Y value calculation process when new tiles were to be loaded. A thread struct was created containing the thread itself and a receiver for the purposes of transferring the vector of vectors containing the SRTM data. This allowed the retrieval and normalisation of the Y values from the .hgt files to occur on a different thread while the initial data was still being used for the rendering process, allowing for a seamless transition when the old tile ran out and a new tile was referenced. All threads were initialised in the default function of the Terrain struct allowing for plenty of time for the calculation of the new tiles.
3.5 Additional features and improvements
New tile generation
Before this implementation, the user was capable of moving up to 1800 pixels in each direction after the initial render of the srtm tile before the program crashes from lack of data. For this to change several alterations need to be made.
Firstly, the moving directions were alternated to represent cardinal directions with the w key moving the terrain north, the d key east and so on. This change would ensure that the following tile matches with the correct real-life latitude and longitude coordinate tile to be loaded based on the cardinal direction that user would be moving to. This implementation would additionally simplify the addition of a GPS system moving the surface plane. Subsequently, the instantiation process of a thread was altered to require latitude and longitude coordinates as parameters, which would be converted to string used to load the corresponding .hgt file. Therefore, when the terrain struct is instantiated an initial thread is called to be created with base latitude and longitude coordinates, while a thread corresponding to the one north of it would be called with latitude plus one and longitude (Table 3.2). 




North-west
(Lat+1, Lon+1)	North 
(Lat+1, Lon)	North-east
(Lat+1, Lon-1)
West 
(Lat, Lon+1)	Initial 
(Lat, Lon)	East
 (Lat, Lon-1)
South-west 
(Lat-1, Lon+1)	South 
(Lat-1, Lon)	South-east
(Lat-1, Lon-1)
Table 3.2- Breakdown of thread instantiation with their latitude and longitude parameters based on the cardinal direction on a 3x3 Matrix.
Following this, the process of retrieving the y value based on the x and z coordinates was altered. The first alteration that was made was calculating the new x and z values by adding to the original values of the numerical amount moved by the user, and the offset of each chunk. The x and z values previously ranged from 0 to 3600 which correspond to the size of the srtm file. To add all other directions, the new values must range from -1800 to 5400 corresponding to half the size of the new tile that can be generated in each direction. Match cases for the new x and z values were created which corresponded to the following: from values 201 to 3400 the y value is retrieved normally from the “mappeddata” vector. When the x or z value is either less than 201 or more than 3400, the data from the corresponding cardinal direction would be retrieved from the corresponding thread and assigned to a new vector named “mappeddatanext” which is stored in the struct. For example, if the z value reaches 200 the north tile is retrieved from the north thread. By that point, the thread has finished the retrieval from the .hgt file so this assignment is seamless. If either the new x or new z or both values exceed the current srtm files coordinates - which means they are either lower than 0 or higher than 3600 - the y value will be retrieved from the “mappeddatanext” vector. Depending on which value exceeded the initial file, and from which side of the spectrum, it will either be added or subtracted with 3600 to fit within the index of the new vector. For example, if the new z value is determined as 4000, the south tile would be assigned to the “mappeddatanext” vector and the values used to find the y value would be x as it is and z 400. Once the x or z value reaches half of the new tile generated, the initial vector is assigned as the “mappeddatanext” vector. Then, the corresponding latitude and longitude coordinates are updated and the threads that correspond to the old surrounding tiles are transferred to new surrounding tiles. This assignment is done halfway into the new tile to ensure that no chunk will require data from the initial tile. 
The case of more than one additional tile being required for the rendering process was considered.  Therefore, three additional vectors of vectors were added for each cardinal direction along with four more threads corresponding to combinations of cardinal directions (e.g. the northeast thread). This was done to account for all possible directions the user can move in, concluding in a three by three tile that can be loaded at all times without delaying the rendering process. To determine the correct vector that the y value has to be retrieved from, four Boolean values corresponding to the four cardinal directions were used and the possibility of two Boolean values being true allowed for the representation of all additional directions. 
Improving accuracy to real world
A significant aspect of this artefact is its ability to accurately represent the terrain that is rendered, and resemble the moving pattern of a light aircraft as closely as possible.
The first improvement that was implemented was adding a water level plane. This would allow for all values that are below a certain threshold to be represented by a smooth plane without minor alterations in the height level. Additionally, these minor alterations would be exaggerated with the alteration of the aspect ratio. The aspect ratio is a representation of the proportions between a rendered object’s width (W) to height (H) and can be denoted as W/H. To determine the ideal value for the aspect ratio, a new value was added to the state struct that allowed for its alteration while the application was running. It was determined that the ideal aspect ratio was 100. This would showcase the valleys and peaks, significantly boosting their visibility, without rendering them out of proportion. This number matches the amount the height is divided by during the normalisation process. Once the ideal number for the aspect ratio was determined, the function to augment and diminish the aspect ratio using keyboard inputs was removed. 
To improve the way the user traverses through the terrain, a looking direction struct was created of camera position struct. This consisted of a x, y and z value that the camera would point to. With each movement of the terrain to a certain direction the camera look direction would move two pixels towards that position. This process would be repeated until the looking direction became parallel to the axis the user would move to. This process was later separated from the users movement with the w, a, s and d keys to the arrow directional keys. To ensure that no chunk is loaded without being visible when the look direction is alternated, the position of the camera is altered concurrently with the looking direction forming a cyclical pattern on the rendered plane (Figure 3.4).
The current process of rendering the terrain colour using the vertex position and the colormap is resource and time efficient, however, it does not provide a high level of realism and does not portray depth at accuracy. This could be solved with the implementation of texture mapping. Texture mapping allows for the overlay of an object (usually an image) to be placed on top of the object rendered. In this case, a very large sized image depicting all road ways and manmade structures of Scotland would be required to add the necessary level of realism and depth to the terrain rendered. This process would additionally significantly slow down the rendering process. In place of this, it was deemed ideal for the implementation of texture mapping to be effectuated through a white grid like structure overlaid on the terrain. This would significantly increase the depth perception of the user without notably slowing down the rendering process. This was achieved using a secondary render pipeline which allowed for the overlay of the grid on the colormap pipeline, enabling the user to toggle between the grid being visible and not being displayed. The grid itself was effectuated by iterating through the data using a specific increment dependent on the level of detail and assigning that position to the secondary pipeline paired with the colour white. 
 
Figure 3.4- Cyclical pattern of camera based on the looking direction (black dot representing the camera position looking inwards towards the moving position)
Testing Implementations
The most indicative metric to depict the performance of the terrain generating and rendering process is by measuring the frame rate, otherwise known as the frames per second (FPS). This metric, as the name describes, measures the amount of frames a program can calculate and render each second. For a smooth and realistic visual experience, it is suggested to reach roughly sixty frames per second (Lenovo, no date). To measure this internally, a separate struct was created that is instantiated with the creation of the main state. This struct utilises time and VecDeque from the standard Rust library (Rust, 2024). VecDeque is a double-ended queue time, and each instant a time value is pushed into the queue and at every second the length of the queue is measured and displayed to the user through the terminal depicting the frames per second.
Once a metric to measure the performance of the rendering process has been achieved, certain test cases can be implemented to determine the most efficient manner in which the terrain can be rendered. 
The rendering process itself is achieved using the GPU as it is the most efficient processing unit for graphics rendering, however, the calculation process to find the vertex data can also occur within the GPU with the use of a compute buffer that reads WGSL to execute code.
A significant drawback of utilising high LOD for the calculation of the y value in the vertex data generation process is a jittering effect that occurs on rendered points. This was caused by the moving distance of the user along the plain being lower than the increment count that the calculations were incremented by, therefore changing the starting position and altering the data. Another solution separate to altering the moving distance was to apply the LOD incrementation directly to the retrieval of the Y values from the .hgt files. This process of rendering was implemented for testing purposes and can be activated using the left control key.
 
Chapter 4 Results
In this section the result of each optimisation to either the efficiency of the rendering process or the resemblance of real-world terrain depicted is described. The success level of the rendering efficiency is measured using the FPS metric calculated. The resemblance to real world topography is evaluated using a comparative approach to the depicted topography of the surface in equivalent coordinates.
4.1 Rendering efficiency performance
To gather the results of the rendering efficiency, the FPS was considered as the dependent variable. The controlled variables constituted the time the task would be run for (which was approximately ten seconds (Used to find the average FPS)), the state the rendering process is in (whether it is idle or receiving user inputs), the SRTM tile used to generate the height map, the view distance covered (four by four chunks) and the device used for the code execution process. The independent variables constituted the type of rendering method used. These consisted of no implementations to improve efficiency, LOD with level varying from one to eight in the y value calculation process from the vector of vectors, LOD in the same process but on the .hgt file retrieval process (represented as LOD2).The measurements were not taken for the computing process occurring on the GPU through a compute buffer as there was no way of interaction between the .hgt files and WGSL. These results are depicted in Table 4.1 








Method	No Improvements	Chunks No LOD implementation
Idle FPS (Frames/s)	107.4 	163
Moving FPS (Frames/s)	1.6	13.4
Method	LOD 1	LOD 2	LOD 3	LOD 4	LOD 5	LOD 6	LOD 7
Idle FPS 
(Frames/s)	165 	166	165	163	167	166	166
Moving FPS (Frames/s)	27.2	56.0	84.9	132.0	163.3	165.0	165.0
Method	LOD2 1	LOD2 2	LOD2 3	LOD2 4	LOD2 5
Idle FPS (Frames/s)	160	166	163	164	166
Moving FPS (Frames/s)	2.0	2.4	2.7	2.2	3.4
Table 4.1 Table containing FPS measurements
4.2 Terrain accuracy 
To determine the level of accuracy that the topography of the rendered terrain has compared to real world terrain, two approaches were taken. Firstly, terrain topography was compared against surfaces from the pilot’s point of view. This was tested against Google Earth images from the same place and pilot positioning. Subsequently, the camera position was set to the highest level possible without the surface plane starting to de-render due to distance. This was done to emulate a satellite view of the entire chunk generated, therefore allowing for the visual comparison of the general topography of the area against similar tools such as Google Maps or Topography-Maps.
To validate the realism of the render from the pilot’s point of view, the artefact was run with the latitude set to 55 and the longitude to 5. This allowed for the navigation of the camera to the north-east side of the Isle of Arran where Figure 4.1 was taken. The same position was taken on Google Earth demonstrated in Figure 4.2.
  
Figure 4.1- North east side of Arran generated by artefact
  
Figure 4.2=Screenshot taken from Google Earth software on 28/04/2024
The first satellite view comparison was done using the River Tay as a reference point around the Newburgh, Port Allen area to confirm that the water level is accurately represented. This area was chosen due to its distinct coastline and also due to Mugdrum Island, which demonstrates a low altitude that can be interpreted as below the water level line. (Figure 4.3)
 
Figure 4.3- Satellite view comparison
Figure 4.3 additionally is useful in determining the height level of the topography represented by the colormap shown by the different peaks and valleys in the south of the River Tay. Figure 4.3 was compared with Figure 4.4 which was taken from the same area on a topographic map of the area.
  
Figure 4.4- Equivalent topography of the area taken from Topographic-map.com
Following this, the next satellite capture was taken off the coast of Troon, incorporating the west side of the Isle of Arran. This section was chosen due to the high level of altitude difference on the Isle of Arran and distinct topography of the area (Figure 4.5).
  
Figure 4.5- Isle of Arran-Troon area screenshot from artefact.
The comparison was made with Figure 4.6 which was taken using Google maps with the topography displayed.
 
Figure 4.6- Figure 4.5’s equivalent taken from “Google maps”
 
Chapter 5 Discussion
	In this sections, all previously mentioned results are analysed and interpreted upon to determine how the artefact performs in relation to the research question, and the aims and objectives set previous to the commencing of the development process. Additionally, the limitations the artefact faces are discussed with the aid of the literature review to determine possible solutions to said limitations. 
5.1 Results
Rendering Efficiency
The results of this study are separated into two categories. Firstly, the rendered terrain accuracy compared to its real-world counterpart, and secondly, the overall efficiency of the rendering process. 
The results in the realm of rendering efficiency depicted by (Table 4.1) showcase high levels of efficiency. Firstly, the base rendering process with no efficiency implementations produces 107.4 frames per second in an idle scenario, which could be considered adequate, however, on a setting where the user presses a key constantly for the span of 10 seconds the fps averaged to 1.6 frames. This frame rate would render the application unusable in a real-world scenario. The implementation of chunks significantly increased efficiency on both the application being idle, and while receiving inputs from the user, where idle frame-rate averaged to 163 frames while the moving frame rate averaged out to 13.4 frames per second. This iteration consisted of the highest detailed terrain depiction and could theoretically be utilised in a real world setting, however, the user would still experience a significant amount of delayed rendering response. 
From this point onwards the idle FPS was capped to about 165 frames per second. This was due to the hardware within the laptop that ran the artefact, and denotes that when idle the rendering process is running as efficiently as possible. Therefore, the focus on improving efficiency was set to the FPS during the terrain altering process. 
The most significant improvement on efficiency was due to the implementation of LOD. With the level of detail set to one (therefore the increment equalling two) the average fps depicted was 27.2 frames, doubling the efficiency of the y value retrieval process. As the level of detail increased the frame-rate also increased in a linear manner. When the LOD was augmented to two, the frame-rate doubled once more to 56 frames per second. This LOD increment provided a smooth experience for the user without significantly reducing the quality of the terrain generated. With LOD set to three, the FPS averaged out to 84.9 frames. This LOD increment provides a very stable and smooth experience with only little change to the quality of the terrain rendered, and would be ideal for current lower-end hardware. Past this point, the increase of LOD increments caused the performance to significantly increased, reaching a plateau of around 163 frames with LOD level set to 5 signifying no difference between the application being idle or receiving constant user inputs. However, a significant drawback with the increase of LOD increments past four is the terrain distortion that results from the LOD implementation. As seen on Figure 5.1 the largest portion of distortion in the quality of the topography depicted occurs from LOD level 5 to LOD level 7. Therefore, the ideal increment for use within a light aircraft depending on the hardware utilised for the rendering process would be LOD set to 3 for more powerful devices or LOD set to 4 for less powerful ones. 
 
Figure 5.1-  Screenshot taken from the artefact with varying LOD (depicted on the image)
The second implementation of LOD withing the .hgt file retrieval process proved not to provide any significant improvements, with the frame-rate being about two to three frames for all varying levels. This is due to the process of retrieving the y values from the .hgt files on different threads than the rest of the artefact, and the smaller size of data within the vector of vectors didn’t affect the performance since the size of the chunk that the terrain was rendered on remained unchanged. This resulted in the surface plane depicting a larger area, ranging from two to five times larger than the original one (depending on the increment used). This implementation could potentially increase the efficiency if the size of the area depicted was reduced. However, this has a significant drawback of displaying all topographic objects smaller than their real-life counterparts. This could be altered on future iterations of the artefact to allow for the correct depiction of the surface (Figure 5.2). 
 
Figure 5.2 -LOD2 with increment set to 3 in the same position as Figure 5.1
Terrain accuracy
The accuracy of the terrain depicted from the pilot’s point of view (shown in Figure 4.1) closely resembles the real-life depiction (Figure 4.2). It can be noted that the central peaks representing the mount Lochan resemble those taken from Google Earth. Additionally, the small hill on the right side of the image is correctly represented. Finally, the overall coastline in both images match, ensuring a good level of accuracy to its real-life counterpart. However, it can also be noted that the overall height of the rendered object is slightly higher than depicted in real-life. This signifies that the aspect ratio was set too high, which can easily be altered by slightly decreasing it from 100.
The terrain depicted from satellite view (Figure 4.3) shows very promising results in the overall accuracy of the terrain. This is based on the high level of resemblance between Figure 4.3 and Figure 4.4’s depiction of the River Tay’s and Mugdrum Island’s coastline. Furthermore, the depiction of the peaks next to Newburgh, where two mountains are separated by a road within a valley that continues across the entire image was depicted with a high level of resemblance.
On Figure 4.5, the topography of Troon and the Isle of Arran are depicted and can be compared to Figure 4.6. It can be noted that the height levels depicting the mountains within Isle of Arran are correctly placed, depicting a very similar topography to its real-life counterpart. In Addition, on the Troon coastline from the side of mainland Scotland, the accuracy of the rendered outcome very closely simulates the coastline on the map, where even the smaller islands off the coast are clearly and correctly depicted.
As described above the accuracy, of the rendered terrain closely resembles that of the its real life counterpart, however, there are still some minor differences depicted. This can be explained by two factors. Firstly, the normalisation process of the data. This process occurs to ensure a smooth plane is rendered, confirming that the transition between tiles loaded doesn’t create unrealistic structures but can result in certain points near the water level being normalised with the water level creating said inconsistencies. Secondly, the SRTM data was collected in February 2000. Since the data was collected twenty-four years ago, certain changes could have occurred in the topography within that time. These could be either man-made, such as artificial extension of a coastline or naturally occurring, such as the shift of a river channel.
5.2 Aims and Objectives
In terms of the aims and objectives set out to be achieved with the implementation of this artefact, this project can be considered very successful as all objectives were completed with varying levels of success.
The first aim that was to choose an appropriate programming language and graphics render API. This was achieved: the final choice for programming language was Rust, and the choice for graphics API being WGPU. Both choices offered a very high level of control over the hardware resources used, which resulted in a highly efficient rendering process overall. Both choices also showed very promising signs of longevity on both aspects of continuing to be maintained, and being utilised in large scale projects. Although this choice of language and graphics API significantly increased the complexity of development, the overall outcome of their collaboration was very positive. 
Following, this the second of understanding the core concepts of the rendering process with the goal of rendering the terrain as efficiently as possible was also achieved successfully. However, further improvements could be made to make the rendering process even more efficient. The level of efficiency currently achieved is a frame-rate of 60 frames per second, which can be reached without having to sacrifice much of the details portrayed in the rendered object. Comparing these results to the original Airsafe project for a low level of detail area with a view distance of 6km, the maximum FPS reached with a high spec device of the time was 60. In this instance, the view distance covered was a four-by-four chunk grid which equates to roughly 500km2 (Appendix A). This translates to a 500km view distance when the camera is positioned at the edge of the terrain generated. 
Subsequently, the following aim of determining an efficient manner in which the geographical data can be retrieved and accurately depict the terrain that is modelled was completed successfully. The use of SRTM data with the ‘srtm’ rust crate allowed for the retrieval of all data collected from that mission. The use of multithreading allowed for this process to occur efficiently. As depicted in section 4.2, the data retrieved from the .hgt files accurately represent their real life counterpart. Additionally, compared to original Airsafe prototype where the highest quality digital elevation model required 160GB of memory to represent mainland UK, in this case 1.5 GB are required to store the data to represent the same area. 
The subsequent objective set consisted of identifying the useful data that the aircraft could provide. That data was determined as the cardinal directions that are depicted in the heading indicator, and were implemented to represent the direction the terrain was moving towards. The altitude is displayed in an altimeter and is represented with the y value in the “camera” struct. The looking direction of the aircraft in relation to the horizon is depicted in an attitude meter and is represented by the y value within the “camlook” struct. Finally, the latitude and longitude coordinates that could be retrieved using an additional GPS device and are utilised to instantiate the threads that retrieve the data that tile is generated by. All these metrics, excluding the latitude and longitude coordinates, could be retrieved from the instruments contained in the light aircraft’s panel with the use of an analogue to digital converter. 
Finally, the last objective that was set was the implementation of all researched topics into one artefact with the criteria of maintaining high efficiency and high terrain accuracy. As mentioned in section 5.1, the efficiency of the rendering process and accuracy of the terrain depicted is significant with the metrics retrieved showing promising results.
5.3 Research significance
The performance of the artefact confirms the improvements mentioned in section 2.3 by the efficiency of the rendering process  significantly increasing showcased. The best performing implementation was with high LOD and the use of chunks to render the terrain. 
Furthermore, this implementation of the 3D terrain rendering process would significantly improve the performance of the original AirSafe project (Section 2.6) if it were implemented in Rust using WGPU. This would also allow for its continued development over the following years as both Rust and WGPU show promising signs of being actively maintained in the future.
5.4 Limitations
A significant drawback that this implementation faces is the SRTM data file size reaching 800 GB for the storage of the .hgt files that contain data for the entire world. However, the files were downloaded in a zipped format that totalled 82 GB. Therefore, with further development the storage of the entire world data could be plausible.
 
Chapter 6 Conclusion and Future Work
6.1 Conclusion
In conclusion, the aim of the project achieved and the implementation process completed several inferences were drawn. Firstly, the decision to use Rust as the main programming language used was a good choice as shown by the results achieved. However, certain aspects of the development of the artefact proved to be more complex than anticipated due to the lack of documentation such as the implementation of threads or certain cargo crates. Overall, the use of Rust yielded positive results especially in the efficiency of the artefact. This was mainly due to the fact that Rust is so low level and allows for full control over the memory allocated. Additionally, this high level of efficiency can be attributed to the fact that WGPU provides control over the resource management, pre-execution preparation and execution processes. Finally, this higher level of efficiency in the rendering process compared to the original AirSafe project can be greatly attributed to the evolution in both the hardware used (with the device considered high spec in 2009 being comparable to a modern low spec device), and the rendering techniques utilised. This demonstrates the need for the tools used to develop this artefact being actively maintained for the foreseeable future.
The artefact was also designed with the goal of being easily usable while also implementing all controls in future iterations automatically without the use of keyboard inputs, however, the artifact in its final stage allows for the following controls (Table 6.1).








Key Pressed	Function Triggered
W	Moves the terrain by the LOD increment count North
A	Moves the terrain by the LOD increment count West
S	Moves the terrain by the LOD increment count South
D	Moves the terrain by the LOD increment count East
Q	Moves the camera looking direction positively along the y axis (Aim Up)
E	Moves the camera looking direction negatively along the y axis (Aim Down)
R	Increases LOD (Up to 7)
F	Decreases LOD (As low as 0)
pageup	Moves camera and camera looking direction positively along the y axis (Go up)
pagedown	Moves camera and camera looking direction negatively along the y axis (Go down)
Up Arrow	Moves the camera as south as possible and faces North
Right Arrow	Moves the camera as west as possible and faces East
Down Arrow	Moves the camera as north as possible and faces south
Left Arrow	Moves the camera as east as possible and faces West
Space	Enables/Disables grid texture
L control	Enables/Disables LOD implementation in the retrieval of y value from .hgt file
Table 6.1- Final keyboard inputs
6.2 Further work
Although with the current implementation the project achieves the aims set out in the beginning, there are further improvements that can be applied to the artefact.
Firstly, incorporating a GPS system that allows for the tracking of the aircraft’s position would allow for the automatic traversal of terrain without having to press a keyboard input. This implementation wouldn’t be very complex as the artefact already utilises latitude and longitude coordinates and could be applied using a GPS mouse or any equivalent GPS hardware, such as a MAX-M8 series, with the use of the “gpsd_proto” cargo crate (gpsd_proto - crates.io: Rust Package Registry, 2023).
Secondly, to combat the large file size that is required to depict the topography of the entire earth, a script could be run at the same time as the application. That script would determine the closest .hgt files to the current latitude and longitude coordinates traversed and unzip them. Once the aircraft has moved past these coordinates the script would delete said files. This would allow for the storage of the .hgt files in a zipped format, significantly reducing the storage required.
Additionally, to improve the depth perception and information depicted by the rendered terrain, a map could be utilised as a texture in place of the white grid texture. This would also be an option that could be toggled on and off such as the already implemented texture, and would allow the pilot to also identify man-made structures. This additional feature, however, could significantly reduce the efficiency of the rendering process, as another render pipeline would be required to be utilised with the vertex data needing to be passed to it. 
Subsequently, some minor parameter tuning is required such as the aspect ratio for a true 1 to 1 accuracy of terrain depicted to its real-life counterpart. Furthermore, adding certain HUD elements such as in the original AirSafe project to provide the aircraft’s pilot with additional information. 
Finally, the overall rendering efficiency could be further improved. This would require more tests to be run to determine the ideal rendering process. There are two potential implementations discussed below that could be tested. Firstly, the use of additional threads that would calculate the vertex data for half of the chunks, while the other half of the chunk vertex data is concurrently being calculated on the main thread. Secondly, implementing varying LOD within the retrieval process of the .hgt files, and the calculated y value repeated for its following point the amount equivalent to the LOD value set. This would remedy the reduced size of the terrain depicted by LOD2 and potentially improve the rendering efficiency. 
List of References
Air Transport Action Group (2016) Aviation Benefits, Aviation Benefits. Available at: https://aviationbenefits.org/ (Accessed: 12 October 2023).
Bernardin, T. et al. (2010) ‘Real-time Terrain Mapping’, p. 14 pages. Available at: https://doi.org/10.4230/DFU.SCIVIZ.2010.275.
Bevy Engine (2024). Available at: https://bevyengine.org// (Accessed: 8 April 2024).
gpsd_proto - crates.io: Rust Package Registry (2023). Available at: https://crates.io/crates/gpsd_proto (Accessed: 30 April 2024).
Instruments | How Things Fly (no date). Available at: https://howthingsfly.si.edu/flight-dynamics/instruments (Accessed: 6 April 2024).
Jack Xu (2023) WGPU by Examples. Available at: https://drxudotnet.com/Home/BookDetails?bookId=1058#Overview.
Jochen Gortler (2018) srtm - crates.io: Rust Package Registry. Available at: https://crates.io/crates/srtm/0.1.0 (Accessed: 28 April 2024).
Kernfeld, P. (2024) ‘paulkernfeld/glx’. Available at: https://github.com/paulkernfeld/glx (Accessed: 8 April 2024).
Kösters, T. (2024) ‘timokoesters/nbodysim’. Available at: https://github.com/timokoesters/nbodysim (Accessed: 8 April 2024).
Lenovo (no date) FPS: What is an FPS? | How does FPS work? Do all PC games use FPS? | Lenovo UK. Available at: https://www.lenovo.com/gb/en/glossary/fps/ (Accessed: 25 April 2024).
Liam McBrien (2009) ‘AirSafe’.
Linus Torvalds (2022) Rust added Linux kernel source tree. Available at: https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=8aebac82933ff1a7c8eede18cab11e1115e2062b (Accessed: 12 October 2023).
Nichat, M. (2013) ‘Landmark based shortest path detection by using A* Algorithm and Haversine Formula’.
Rust (2024) VecDeque in std::collections - Rust. Available at: https://doc.rust-lang.org/std/collections/struct.VecDeque.html (Accessed: 29 April 2024).
Rust By Example (no date). Available at: https://doc.rust-lang.org/rust-by-example/index.html (Accessed: 18 March 2024).
The Rust Programming Language (no date). Available at: https://doc.rust-lang.org/book/ch00-00-introduction.html (Accessed: 9 October 2023).
Universal Avionics (2020) ‘InSight Display System’.
USGS (2008) ‘SRTM Guide’.
Veloren (2019). Available at: https://veloren.net (Accessed: 8 April 2024).

 
Appendices 
Appendix A Translating a four-by-four grid of chunks to kilometres
The test case was run on the latitude by longitude grid 550, 50. Using the haversine equation (Nichat, 2013) the distance covered by one degree of latitude (111.2 km) and the distance covered by one degree of longitude (63.78 km) can be calculated and then multiplied to determine the area of that latitude longitude grid (7092 km2). Following that the area of total points within a .hgt file has to be calculated by multiplying the width (3600) with the height (3600) which equals 12960000. By dividing the latitude and longitude grid area with the total points withing a .hgt file the area depicted by each point can be calculated (5.472481e-4). This number can then be multiplied by the total points within a chunk (57600) to determine the area displayed by one chunk (31.52149 km2). To find the total points within a chunk its width (240) and height (240) are multiplied. Finally, the area displayed by one chunk is multiplied by the total number of chunks (16) to determine the total area displayed by the four-by-four grid of chunks (504.34 km2).
Appendix B Hardware utilised for the tests ran 
The device utilised to run the test was a high-end at the time gaming laptop purchased in 2021.
CPU: Intel Core i7-11800H (8 cores, 16 threads, 4.6 GHz)
GPU: GeForce RTX 3060 Mobile
RAM: 16 GB
Storage: 1024GB SSD (M2)
